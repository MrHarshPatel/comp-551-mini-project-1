{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r adult_data_export\n",
    "%store -r ionosphere_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, num_iter, lr=0.01, eps=1e-2):        \n",
    "        # initialize hyperparameters \n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.num_iter = num_iter\n",
    "        self.w = []\n",
    "        \n",
    "    def add_intercept(self, X):\n",
    "        N,D = X.shape\n",
    "        intercept = np.ones((N, 1), dtype = X.dtype)\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "        \n",
    "    def sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = self.add_intercept(X)\n",
    "        N,D = X.shape\n",
    "        self.w = np.zeros(D)\n",
    "        \n",
    "        g = np.inf \n",
    "        \n",
    "#         while np.linalg.norm(g) > self.eps:\n",
    "        for i in range(self.num_iter):\n",
    "            yh = self.sigmoid(np.dot(X, self.w))\n",
    "            g = np.dot(X.T, (yh - y)) / N\n",
    "            self.w = self.w - self.lr*g\n",
    "            \n",
    "        print(self.w)\n",
    "\n",
    "    \n",
    "    def predict(self, X):     \n",
    "        X = self.add_intercept(X)\n",
    "#         N,D = X.shape\n",
    "        yh = self.sigmoid(np.dot(X, self.w))\n",
    "        predictions = (yh >= 0.5).astype(int)\n",
    "        return predictions\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.47677632  4.10378366  1.79915035  0.44720796  2.35662701  2.38443023\n",
      "  0.71065584  2.1170081   1.95156925 -0.12762739 -1.60946535 -0.80850208\n",
      " -0.69233023  1.04337252  1.9133137  -0.62925869  0.48433397  1.08480976\n",
      " -1.67962158 -0.26349847 -0.16474806 -3.03079192  1.56647666  1.21703613\n",
      "  1.12145749  1.17313858 -3.31192043 -0.47242375  1.02282308  1.77301618\n",
      "  0.89800871 -0.52073043 -0.62298589 -1.81501739]\n"
     ]
    }
   ],
   "source": [
    "# np.random.shuffle(adult_data_export)\n",
    "\n",
    "train_X = ionosphere_export[:300, :-1]\n",
    "train_y = ionosphere_export[:300, -1]\n",
    "\n",
    "test_X = ionosphere_export[300:, :-1]\n",
    "test_y = ionosphere_export[300:, -1]\n",
    "\n",
    "lr = LogisticRegression(100000)\n",
    "lr.fit(train_X, train_y)\n",
    "# lr.predict(np.matrix([[1,1,-0.02401,0.94140,0.06531,0.92106,-0.23255,0.77152,-0.16399,0.52798,-0.20275,0.56409,-0.00712,0.34395,-0.27457,0.52940,-0.21780,0.45107,-0.17813,0.05982,-0.35575,0.02309,-0.52879,0.03286,-0.65158,0.13290,-0.53206,0.02431,-0.62197,-0.05707,-0.59573,-0.04608,-0.65697],[1,1,-0.02401,0.94140,0.06531,0.92106,-0.23255,0.77152,-0.16399,0.52798,-0.20275,0.56409,-0.00712,0.34395,-0.27457,0.52940,-0.21780,0.45107,-0.17813,0.05982,-0.35575,0.02309,-0.52879,0.03286,-0.65158,0.13290,-0.53206,0.02431,-0.62197,-0.05707,-0.59573,-0.04608,-0.65697]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.45060015  1.36951723  0.54924486  1.453835    0.98838284  0.61643534\n",
      "   1.15601183  0.92003814  0.10362771 -0.69386292 -0.26642617 -0.25798127\n",
      "   0.61058957  0.69665885 -0.07041313  0.19491267  0.51932933 -0.44789273\n",
      "  -0.03623637  0.04729717 -1.6872867   0.7681082   0.49400573  0.44460284\n",
      "   0.8108387  -1.81564741 -0.25972062  0.37849224  0.61999387  0.53650855\n",
      "  -0.27720725 -0.26619831 -0.8946646 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr2 = linear_model.LogisticRegression()\n",
    "lr2.fit(train_X, train_y)\n",
    "\n",
    "print(lr2.coef_) # returns a matrix of weights (coefficients)'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
